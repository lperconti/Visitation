{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset, take a look at the data info: \n",
    "df_1 = pd.read_csv('Data/DF_1_clean.csv')\n",
    "df_1.set_index('Date', inplace=True)\n",
    "df_2 = pd.read_csv('Data/DF_2_clean.csv')\n",
    "df_2.set_index('Date', inplace=True)\n",
    "df_3 = pd.read_csv('Data/DF_3_clean.csv')\n",
    "df_3.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resort 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model\n",
    "Linear Regression with Cross Validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into test and train X and Y\n",
    "X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "y = df_1['TOTAL_VISITS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-12-21    432.0\n",
       "2017-12-22     48.0\n",
       "2017-12-23    266.0\n",
       "2017-12-24    283.0\n",
       "2017-12-25    281.0\n",
       "Name: TOTAL_VISITS, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization of target - Visits\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(y, bins=100);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: {'fit_time': array([0.0324769 , 0.02553225, 0.02359891]), 'score_time': array([0.01517701, 0.02217674, 0.01897621]), 'test_score': array([0.35521544, 0.44897868, 0.44931362]), 'train_score': array([0.55955406, 0.51543235, 0.5481807 ])}\n",
      "mean CV Score: 0.41783591380107216\n"
     ]
    }
   ],
   "source": [
    "#Split into test and train X and Y\n",
    "# X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "# y = df_1['TOTAL_VISITS']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t('scaler', StandardScaler(), non_cat),\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#setting up the pipe and training the model: \n",
    "\n",
    "LRPipe = Pipeline([('trans', Transformer),\n",
    "                ('linreg', LinearRegression())])\n",
    "\n",
    "LRPipe.fit(X_train, y_train)\n",
    "\n",
    "#cross validation and scoring\n",
    "cv = cross_validate(LRPipe, X_train, y_train, return_train_score=True, cv=3)\n",
    "cv_score = cross_val_score(LRPipe, X_train, y_train, cv = 3)\n",
    "\n",
    "print(f'Cross Validation Scores: {cv}')\n",
    "\n",
    "print(f'mean CV Score: {cv_score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Encoding and scaling, the Basic Linear Regression CV score is 0.418\n",
    "\n",
    "There is definitly some room for improvement! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Combination for Tree Regressor Found During Grid Search:\n",
      "{'dtr__max_depth': 7, 'dtr__min_samples_split': 10, 'dtr__splitter': 'best'}\n",
      "Tree Grid Cross Validation Scores: {'fit_time': array([1.7129879 , 1.77686095, 1.69458604]), 'score_time': array([0.00824189, 0.0036962 , 0.00476289]), 'test_score': array([0.43429782, 0.47071407, 0.28483747]), 'train_score': array([0.88152865, 0.83650799, 0.82616951])}\n",
      "Tree Grid mean CV Score: 0.39661645429417974\n"
     ]
    }
   ],
   "source": [
    "#Split into test and train X and Y\n",
    "X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "y = df_1['TOTAL_VISITS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t# ('scaler', StandardScaler(), non_cat), #no need to scale on Trees\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "TreeRegPipe = Pipeline([('trans', Transformer),\n",
    "                        ('dtr', dtr)])\n",
    "\n",
    "dtr_param_grid = {\n",
    "\t'dtr__splitter': ['best', 'random'],\n",
    "    'dtr__min_samples_split': [4, 6, 8, 10],\n",
    "    'dtr__max_depth': [4, 5, 6, 7, 8]\n",
    "}\t\t\n",
    "\n",
    "#set up gridsearch:\n",
    "TreeGrid = GridSearchCV(estimator=TreeRegPipe,\n",
    "\t\t\t\t\t\t  param_grid=dtr_param_grid,\n",
    "\t\t\t\t\t\t  cv=3)\n",
    "\n",
    "TreeGrid.fit(X_train, y_train)\n",
    "\n",
    "#cross validation and scoring\n",
    "cv = cross_validate(TreeGrid, X_train, y_train, return_train_score=True, cv=3)\n",
    "cv_score = cross_val_score(TreeGrid, X_train, y_train, cv = 3)\n",
    "\n",
    "print(\"Best Parameter Combination for Tree Regressor Found During Grid Search:\")\n",
    "print(TreeGrid.best_params_)\n",
    "\n",
    "print(f'Tree Grid Cross Validation Scores: {cv}')\n",
    "\n",
    "print(f'Tree Grid mean CV Score: {cv_score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Regressor did not perform well with the best score of .397 in comparison to linear regression with a score of .418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Combination Found During Grid Search:\n",
      "{'dtr__criterion': 'mae', 'dtr__max_depth': None, 'dtr__max_features': 'auto', 'dtr__n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "#pipeline_3:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# #Split into test and train X and Y\n",
    "# X = df_3_preprocessed.drop(columns=['TOTAL_VISITS'])\n",
    "# y = df_3_preprocessed['TOTAL_VISITS']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t# ('scaler', StandardScaler(), non_cat), #no need to scale on Trees\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: treeregressor\n",
    "rfr = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipeline_3 = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('dtr', rfr)])\n",
    "\n",
    "#set up grid search paramater grid\n",
    "rfr_param_grid = {\n",
    "    'dtr__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    'dtr__max_depth': [None, 2, 3, 4, 5, 6, 8, 10],\n",
    "\t'dtr__max_features': ['auto', 'sqrt', 'log2'],\n",
    "\t'dtr__criterion': ['mse', 'mae']\n",
    "}\n",
    "\n",
    "#set up gridsearch:\n",
    "gridsearch2 = GridSearchCV(estimator=pipeline_3,\n",
    "\t\t\t\t\t\t  param_grid=rfr_param_grid,\n",
    "\t\t\t\t\t\t  cv=3)\n",
    "\n",
    "#fit gridsearch\n",
    "gridsearch2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(gridsearch2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores best Random Forest Regressor: {'fit_time': array([0.10468078, 0.10215998, 0.10118198, 0.11714292, 0.10317492]), 'score_time': array([0.008425  , 0.00471592, 0.00667   , 0.00649691, 0.00496221]), 'test_score': array([0.57028451, 0.64140287, 0.7529616 , 0.68577996, 0.42613841]), 'train_score': array([0.93575578, 0.91772552, 0.91531086, 0.91971138, 0.91446831])}\n",
      "mean CV Score: 0.61531347043847\n"
     ]
    }
   ],
   "source": [
    "#pipeline_3:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Split into test and train X and Y\n",
    "X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "y = df_1['TOTAL_VISITS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t# ('scaler', StandardScaler(), non_cat), #no need to scale on Trees\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: treeregressor\n",
    "rfr = RandomForestRegressor(criterion = 'mae', max_depth = None, max_features = 'auto', n_estimators = 10, random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipeline_3 = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('dtr', rfr)])\n",
    "\n",
    "\n",
    "pipeline_3.fit(X_train, y_train)\n",
    "\n",
    "cv = cross_validate(pipeline_3, X_train, y_train, return_train_score=True, cv=5)\n",
    "cv_score = cross_val_score(pipeline_3, X_train, y_train, cv = 5)\n",
    "print(f'Cross Validation Scores best Random Forest Regressor: {cv}')\n",
    "\n",
    "print(f'mean CV Score: {cv_score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Resort 1, forests are performing better than trees with a CV score of .615!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Combination Found During Gradient Boosting Grid Search:\n",
      "{'gbr__criterion': 'friedman_mse', 'gbr__min_samples_split': 3, 'gbr__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#pipeline_4:\n",
    "\n",
    "#Split into test and train X and Y\n",
    "# X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "# y = df_1['TOTAL_VISITS']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t# ('scaler', StandardScaler(), non_cat), #no need to scale on Trees\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: treeregressor\n",
    "GBR = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipeline_4 = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('gbr', GBR)])\n",
    "\n",
    "#set up grid search paramater grid\n",
    "gbr_param_grid = {\n",
    "    'gbr__n_estimators': [50, 100, 200, 300],\n",
    "    'gbr__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "\t'gbr__min_samples_split': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "#set up gridsearch:\n",
    "gridsearch3 = GridSearchCV(estimator=pipeline_4,\n",
    "\t\t\t\t\t\t  param_grid=gbr_param_grid,\n",
    "\t\t\t\t\t\t  cv=5)\n",
    "\n",
    "\n",
    "#fit gridsearch\n",
    "gridsearch3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameter Combination Found During Gradient Boosting Grid Search:\")\n",
    "print(gridsearch3.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score Gradient Boosting Model: {'fit_time': array([0.09019113, 0.06526279, 0.06683993, 0.06603694, 0.08423114]), 'score_time': array([0.00608301, 0.00390124, 0.00385904, 0.004812  , 0.00417709]), 'test_score': array([0.64582103, 0.72973226, 0.72184128, 0.7821154 , 0.64737244]), 'train_score': array([0.92685098, 0.92960816, 0.92977908, 0.91711137, 0.93585572])}\n",
      "mean CV Score: 0.705376480997786\n"
     ]
    }
   ],
   "source": [
    "#Using best params on a gradient booster regressor then scoring thorugh cross val: \n",
    "\n",
    "#column transformer - this sets up simmilar to pipeline (scaler and transformer)\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t# ('scaler', StandardScaler(), non_cat), #no need to scale on Trees\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: treeregressor\n",
    "# GBR = GradientBoostingRegressor(criterion='mse', n_estimators=200, random_state = 42)\n",
    "GBR = GradientBoostingRegressor(criterion='friedman_mse', n_estimators=100, min_samples_split= 3, random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipeline_gbr = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('gbr', GBR)])\n",
    "\n",
    "pipeline_gbr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv = cross_validate(pipeline_gbr, X_train, y_train, return_train_score=True, cv=5)\n",
    "cv_score = cross_val_score(pipeline_gbr, X_train, y_train, cv = 5)\n",
    "print(f'Cross Validation Score Gradient Boosting Model: {cv}')\n",
    "\n",
    "print(f'mean CV Score: {cv_score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Booster Regressor is doing the best: \n",
    "\n",
    "And more improvement! We got our average model CV score up to .705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Combination Found During Grid Search:\n",
      "{'xgb_r__eta': 0.2, 'xgb_r__max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#x_boost Pipe:\n",
    "\n",
    "# X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "# y = df_1['TOTAL_VISITS']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline first step: Transformer\n",
    "\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t('scaler', StandardScaler(), non_cat),\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: treeregressor\n",
    "xgb_r = xg.XGBRegressor(seed = 123)\n",
    "\n",
    "#pipeline\n",
    "xboostPipe = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('xgb_r', xgb_r)])\n",
    "\n",
    "# objective ='reg:squarederror', n_estimators = 10, \n",
    "boost_param_grid = {\n",
    "    'xgb_r__eta': [.2, .3, .4, .5, .6, .7, .8],\n",
    "\t'xgb_r__max_depth': [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "gridsearch_boost = GridSearchCV(estimator=xboostPipe,\n",
    "\t\t\t\t\t\t  param_grid=boost_param_grid,\n",
    "\t\t\t\t\t\t  cv=5)\n",
    "\n",
    "#fit gridsearch\n",
    "gridsearch_boost.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "print(gridsearch_boost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: {'fit_time': array([0.10541511, 0.05193114, 0.04159904, 0.04817104, 0.04404402]), 'score_time': array([0.00847983, 0.01229191, 0.01034975, 0.00830412, 0.0126729 ]), 'test_score': array([0.60579381, 0.73290358, 0.72137846, 0.81642227, 0.64039896]), 'train_score': array([0.95982675, 0.96375075, 0.96609444, 0.96010115, 0.96666743])}\n",
      "mean CV Score: 0.7033794159155814\n"
     ]
    }
   ],
   "source": [
    "#x_boost Pipe with ideal paramaters:\n",
    "\n",
    "# X = df_1.drop(columns=['TOTAL_VISITS'])\n",
    "# y = df_1['TOTAL_VISITS']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline first step: Transformer\n",
    "cat = ['is_school_out', 'is_holiday', 'day_of_week_num']\n",
    "non_cat = ['T - AWND', 'T - PRCP', 'T - SNOW', 'T - SNWD', 'T - TAVG', 'M_PRCP', 'M_SNWD', 'M_TAVG']\n",
    "\n",
    "Transformer = ColumnTransformer([\n",
    "\t('ohe', OneHotEncoder(), cat),\n",
    "\t('scaler', StandardScaler(), non_cat),\n",
    "\t], remainder ='passthrough')\n",
    "\n",
    "#Pipeline second Step: \n",
    "xgb_r_2 = xg.XGBRegressor(eta = 0.2, max_depth = 3, seed = 123)\n",
    "\n",
    "xboostPipe_2 = Pipeline([('transformer', Transformer),\n",
    "\t\t\t\t\t\t('xgb_r_2', xgb_r_2)])\n",
    "\n",
    "xboostPipe_2.fit(X_train, y_train)\n",
    "\n",
    "cv = cross_validate(xboostPipe_2, X_train, y_train, return_train_score=True, cv=5)\n",
    "cv_score = cross_val_score(xboostPipe_2, X_train, y_train, cv = 5)\n",
    "print(f'Cross Validation Scores: {cv}')\n",
    "\n",
    "print(f'mean CV Score: {cv_score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X boost for resort 1 is preforming about the same as the Gradient Booster Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "**Gradient Booster Regressor** \n",
    "\n",
    "CV score up to .72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738167530522504"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GBR Test Score\n",
    "pipeline_gbr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Booster Regressor gets a test CV score of .774, this means we can account for 77% of the variance in the data with our Gradient Booster Regressor model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Visits</th>\n",
       "      <th>Predicted Visits</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-07</th>\n",
       "      <td>4612.0</td>\n",
       "      <td>4421.515130</td>\n",
       "      <td>190.484870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-04</th>\n",
       "      <td>887.0</td>\n",
       "      <td>1718.004963</td>\n",
       "      <td>831.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>2769.0</td>\n",
       "      <td>2917.148642</td>\n",
       "      <td>148.148642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-07</th>\n",
       "      <td>4072.0</td>\n",
       "      <td>2935.819651</td>\n",
       "      <td>1136.180349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-27</th>\n",
       "      <td>1393.0</td>\n",
       "      <td>1853.388422</td>\n",
       "      <td>460.388422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Real Visits  Predicted Visits   Difference\n",
       "Date                                                  \n",
       "2021-02-07       4612.0       4421.515130   190.484870\n",
       "2021-04-04        887.0       1718.004963   831.004963\n",
       "2019-02-20       2769.0       2917.148642   148.148642\n",
       "2021-03-07       4072.0       2935.819651  1136.180349\n",
       "2020-01-27       1393.0       1853.388422   460.388422"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_boost = pipeline_gbr.predict(X_test)\n",
    "\n",
    "df = pd.DataFrame({'Real Visits':y_test, 'Predicted Visits':y_pred_boost, 'Difference': abs(y_test - y_pred_boost)})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680.7975932095176"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_school_out 0.025351575103521214\n",
      "is_holiday 0.044095493823134074\n",
      "T - AWND 0.0078595078668822\n",
      "T - PRCP 0.002770315723362899\n",
      "T - SNOW 0.003630304218622402\n",
      "T - SNWD 0.015046849206457756\n",
      "T - TAVG 0.0008085034731838031\n",
      "M_PRCP 0.00018606127178336004\n",
      "M_SNWD 0.024309256917961996\n",
      "M_TAVG 0.16566395836282116\n",
      "day_of_week_num 0.1661238930660503\n",
      "month 0.033529529612692566\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(X_train.columns, pipeline_gbr['gbr'].feature_importances_):\n",
    "    print(name, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_0 0.025351575103521214\n",
      "x0_1 0.044095493823134074\n",
      "x1_0 0.0078595078668822\n",
      "x1_1 0.002770315723362899\n",
      "x2_0 0.003630304218622402\n",
      "x2_1 0.015046849206457756\n",
      "x2_2 0.0008085034731838031\n",
      "x2_3 0.00018606127178336004\n",
      "x2_4 0.024309256917961996\n",
      "x2_5 0.16566395836282116\n",
      "x2_6 0.1661238930660503\n",
      "T - AWND 0.033529529612692566\n",
      "T - PRCP 0.00670711305094752\n",
      "T - SNOW 0.02912046300665862\n",
      "T - SNWD 0.0077716566739196745\n",
      "T - TAVG 0.08672645724291084\n",
      "M_PRCP 0.0064209374777957785\n",
      "M_SNWD 0.17026598560975334\n",
      "M_TAVG 0.04147328876189428\n"
     ]
    }
   ],
   "source": [
    "ohe = pipeline_gbr.named_steps[\"transformer\"].transformers_[0][1].get_feature_names()\n",
    "numbers = non_cat\n",
    "\n",
    "columns = [*ohe, *numbers]\n",
    "\n",
    "for name, importance in zip(columns, pipeline_gbr['gbr'].feature_importances_):\n",
    "    print(name, importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-47750d432df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature Importance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19 is out of bounds for axis 0 with size 19"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "feature_importance = pipeline_gbr['gbr'].feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0])\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    pipeline_gbr, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(columns)[sorted_idx],\n",
    ")\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c15d3b161d9e31d3c14101c293414707f40e59d6cae0bbd6b708ca3d1e942f6f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
